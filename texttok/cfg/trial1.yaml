experiment:
    project_name: textok
    exp_name: run2
    max_train_examples: 10000000000
    save_every: 1000
    eval_every: 50000000000000
    sample_every: 500
    log_every: 100
    log_level: info
    resume_path_from_checkpoint: null

model:
    name: textok

dataset:
    name: coco
    params:
        root_path:  /media/pranoy/Datasets/coco-dataset/coco
        num_workers: 4
        pin_memory: True
        batch_size: 1
        persistent_workers: True
        shuffle : True
        train_test_split : 0.9
  

lr_scheduler:
    name: constant_with_warmup
    params:
        learning_rate: ${optimizer.params.learning_rate}
        warmup_steps: 1000
        decay_steps: null

training:
    gradient_accumulation_steps: 16
    mixed_precision: "no"
    seed: 42
    num_epochs: 200
    max_grad_norm: 1.0
